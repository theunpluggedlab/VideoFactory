import os
import json
import sys
import traceback
import re
import numpy as np
from PIL import Image, ImageFont, ImageDraw
import shutil
from datetime import datetime

# [í•µì‹¬ ìˆ˜ì •] Pillow ìµœì‹  ë²„ì „ í˜¸í™˜ì„± íŒ¨ì¹˜
# Pillow 10.0.0ë¶€í„° ANTIALIASê°€ ì‚­ì œë˜ì—ˆìœ¼ë¯€ë¡œ, ì´ë¥¼ LANCZOSë¡œ ë§¤í•‘í•´ì¤ë‹ˆë‹¤.
if not hasattr(Image, 'ANTIALIAS'):
    Image.ANTIALIAS = Image.LANCZOS

# MoviePy Import (v1.0.3 í˜¸í™˜)
try:
    from moviepy.editor import *
    from moviepy.video.tools.subtitles import SubtitlesClip
except ImportError:
    print("âŒ moviepy ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("   ğŸ‘‰ ì„¤ì¹˜ ë°©ë²•: pip install moviepy")
    sys.exit(1)

# í°íŠ¸ ê²½ë¡œ ì •ì˜ (Windows ê¸°ì¤€)
FONT_EN = "C:/Windows/Fonts/arialbd.ttf"
FONT_KO = "C:/Windows/Fonts/malgunbd.ttf"
FONT_DEFAULT = "arial.ttf"

def get_font_path(text):
    if re.search("[ê°€-í£]", text):
        if os.path.exists(FONT_KO): return FONT_KO
        if os.path.exists("C:/Windows/Fonts/malgun.ttf"): return "C:/Windows/Fonts/malgun.ttf"
    if os.path.exists(FONT_EN): return FONT_EN
    return FONT_DEFAULT

def create_highlighted_text_clip(text, fontsize, color='white', highlight_color='yellow', 
                               stroke_color='black', stroke_width=2, 
                               max_width=680, align='center', is_title=False):
    """Pillowë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ í´ë¦½ ìƒì„±"""
    tokens = []
    try:
        if sys.platform == 'win32': text = text.encode('gbk', 'ignore').decode('gbk')
    except: pass

    parts = text.split('*')
    for i, part in enumerate(parts):
        c = highlight_color if i % 2 == 1 else color
        words = part.split()
        for word in words:
            tokens.append({'text': word, 'color': c})

    font_path = get_font_path(text)
    try: font = ImageFont.truetype(font_path, fontsize)
    except: font = ImageFont.load_default()

    dummy_draw = ImageDraw.Draw(Image.new('RGBA', (1, 1)))
    space_w = dummy_draw.textbbox((0, 0), " ", font=font)[2]
    
    lines = []
    current_line = []
    current_w = 0
    for token in tokens:
        bbox = dummy_draw.textbbox((0, 0), token['text'], font=font)
        word_w = bbox[2] - bbox[0]
        if current_line and (current_w + word_w > max_width):
            lines.append(current_line)
            current_line = [token]
            current_w = word_w + space_w
        else:
            current_line.append(token)
            current_w += word_w + space_w
    if current_line: lines.append(current_line)

    line_height = int(fontsize * 1.4)
    total_height = len(lines) * line_height + 20
    canvas_w = max_width + 40
    img = Image.new('RGBA', (canvas_w, total_height), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    
    y = 10
    for line_tokens in lines:
        line_w = 0
        for t in line_tokens:
            w = draw.textbbox((0, 0), t['text'], font=font)[2] - draw.textbbox((0, 0), t['text'], font=font)[0]
            line_w += w + space_w
        line_w -= space_w
        x = (canvas_w - line_w) // 2 if align == 'center' else 10
            
        for t in line_tokens:
            txt = t['text']; col = t['color']
            for dx in range(-stroke_width, stroke_width+1):
                for dy in range(-stroke_width, stroke_width+1):
                    if dx!=0 or dy!=0: draw.text((x+dx, y+dy), txt, font=font, fill=stroke_color)
            draw.text((x, y), txt, font=font, fill=col)
            w = draw.textbbox((0, 0), txt, font=font)[2] - draw.textbbox((0, 0), txt, font=font)[0]
            x += w + space_w
        y += line_height
        
    return ImageClip(np.array(img))

def create_source_label(text, font_path):
    try: font = ImageFont.truetype(font_path, 20)
    except: font = ImageFont.load_default()
    dummy_draw = ImageDraw.Draw(Image.new('RGBA', (1, 1)))
    bbox = dummy_draw.textbbox((0, 0), text, font=font)
    w = bbox[2] - bbox[0] + 20
    h = bbox[3] - bbox[1] + 10
    img = Image.new('RGBA', (w, h), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    x, y = 10, 0
    for dx in range(-2, 3):
        for dy in range(-2, 3):
            draw.text((x+dx, y+dy), text, font=font, fill='black')
    draw.text((x, y), text, font=font, fill='white')
    return ImageClip(np.array(img))

def create_video():
    mode = "video"
    if len(sys.argv) > 1: mode = sys.argv[1]

    is_shorts = "shorts" in mode
    is_news = "news" in mode
    
    story_path = "story.json"
    image_dir = "images"
    audio_dir = "audio"
    intro_path = "assets/intro.mp4"
    outro_path = "assets/outro.mp4"
    
    if not os.path.exists(story_path):
        print("âŒ ì˜¤ë¥˜: story.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    with open(story_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    story_content = data[0] if isinstance(data, list) else data
            title_text = story_content.get("title", "News Briefing")
    scenes = story_content.get("scenes", [])
    
    image_sources = {}
    sources_path = os.path.join(image_dir, "sources.json")
    if os.path.exists(sources_path):
        try:
            with open(sources_path, "r", encoding="utf-8") as f:
                image_sources = json.load(f)
        except: pass

    print(f"=== í¸ì§‘(Editor) ì‹œì‘ (Mode: {mode}) ===")
    
    # 3ë‹¨ ë¶„ë¦¬ ì €ì¥ì†Œ (Intro / Body / Outro)
    intro_clip_final = None
    outro_clip_final = None
    body_clips = []

    final_size = (720, 1280) if is_shorts else (1280, 720)

    for i, scene in enumerate(scenes):
        idx = i + 1
        img_path = os.path.join(image_dir, f"image_{idx}.png")
        aud_path = os.path.join(audio_dir, f"audio_{idx}.mp3")
        
        if not os.path.exists(aud_path):
            print(f"âš ï¸ ì˜¤ë””ì˜¤ ëˆ„ë½ (Scene {idx}), ê±´ë„ˆëœ€.")
            continue

        print(f"ğŸ¬ Scene {idx} í•©ì„± ì¤‘...")
        
        audio_clip = AudioFileClip(aud_path)
        duration = audio_clip.duration
        
        visual_clip = None
        is_video_asset = False
        is_intro_scene = (i == 0 and is_shorts and is_news)
        is_outro_scene = (i == len(scenes) - 1 and is_shorts and is_news)

        # ----------------------------------------------------------------
        # 1. ë¹„ë””ì˜¤/ì´ë¯¸ì§€ ì†ŒìŠ¤ ê²°ì •
        # ----------------------------------------------------------------
        if is_intro_scene and os.path.exists(intro_path):
            print("   ğŸ‘‰ Intro ì˜ìƒ ì ìš© (Looping)")
            vid = VideoFileClip(intro_path)
            # Intro: ì˜¤ë””ì˜¤ ì œê±° í›„ ë£¨í•‘ (ë‚˜ë˜ì´ì…˜ ì˜¤ë””ì˜¤ê°€ ë®ì¼ ì˜ˆì •)
            visual_clip = vid.without_audio().loop(duration=duration)
            is_video_asset = True

        elif is_outro_scene and os.path.exists(outro_path):
            print("   ğŸ‘‰ Outro ì˜ìƒ ì ìš© (Trimming)")
            vid = VideoFileClip(outro_path)
            # Outro: ì˜¤ë””ì˜¤ ì œê±°
            vid = vid.without_audio()
            
            if vid.duration > duration:
                visual_clip = vid.subclip(0, duration)
            else:
                visual_clip = vid.set_duration(duration)
            is_video_asset = True
        
        else:
            if os.path.exists(img_path):
                visual_clip = ImageClip(img_path).set_duration(duration)
            else:
                print(f"âš ï¸ ì´ë¯¸ì§€ ëˆ„ë½ (Scene {idx})")
                continue

        # ----------------------------------------------------------------
        # 2. ë ˆì´ì•„ì›ƒ í•©ì„±
        # ----------------------------------------------------------------
        layers = []
        
        if is_shorts:
            # ê²€ì€ ë°°ê²½
            black_bg = ColorClip(size=final_size, color=(0, 0, 0)).set_duration(duration)
            layers.append(black_bg)
            
            # ë¦¬ì‚¬ì´ì¦ˆ ë° ì¤‘ì•™ ì •ë ¬ (Resize ì—ëŸ¬ í•´ê²°: íŒ¨ì¹˜ ì ìš©ë¨)
            resized_visual = visual_clip.resize(width=720)
            centered_visual = resized_visual.set_position("center")
            layers.append(centered_visual)
            
        else:
            # Video ëª¨ë“œ
            resized_visual = visual_clip.resize(width=1280)
            layers.append(resized_visual)

        # ì¶œì²˜ í‘œì‹œ (ì´ë¯¸ì§€ì¸ ê²½ìš°ì—ë§Œ, Intro/Outro ì œì™¸)
        if not is_video_asset:
            img_filename = f"image_{idx}.png"
            if img_filename in image_sources:
                source_text = f"Source: {image_sources[img_filename]}"
                source_clip = create_source_label(source_text, FONT_EN)
                source_y = 50 if is_shorts else 20
                source_clip = source_clip.set_position(("right", source_y)).set_duration(duration)
                layers.append(source_clip)

        # ìë§‰ í‘œì‹œ (ëª¨ë“  Scene ì ìš© - Intro/Outro í¬í•¨)
        if is_shorts:
            narration = scene.get("narration", "")
            if narration:
                txt_clip = create_highlighted_text_clip(
                    narration, fontsize=45, color='white', highlight_color='yellow', 
                    max_width=650
                )
                txt_clip = txt_clip.set_position(("center", 950)).set_duration(duration)
                layers.append(txt_clip)

        # ê°œë³„ Scene ìµœì¢… í•©ì„± (ë‚˜ë˜ì´ì…˜ ì˜¤ë””ì˜¤ í¬í•¨)
        scene_composite = CompositeVideoClip(layers, size=final_size).set_audio(audio_clip)

        # ----------------------------------------------------------------
        # 3. í´ë¦½ ë¶„ë¥˜ (Intro / Body / Outro)
        # ----------------------------------------------------------------
        if is_intro_scene:
            intro_clip_final = scene_composite
        elif is_outro_scene:
            outro_clip_final = scene_composite
        else:
            body_clips.append(scene_composite)

    if not body_clips:
        print("âŒ ë³¸ë¬¸ í´ë¦½ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # ----------------------------------------------------------------
    # 4. ìµœì¢… ì—°ê²° (Concatenate)
    # ----------------------------------------------------------------
    print("ğŸï¸ í´ë¦½ ë³‘í•© ë° íƒ€ì´í‹€ ì ìš© ì¤‘...")
    
    # [1] ë³¸ë¬¸ ë³‘í•©
    body_concat = concatenate_videoclips(body_clips, method="compose")
    
    # [2] ë³¸ë¬¸ì—ë§Œ íƒ€ì´í‹€ ì˜¤ë²„ë ˆì´ ì ìš© (Intro/Outro ì¹¨ë²” ë°©ì§€)
    if is_shorts and is_news:
        print("   ğŸ“ ë³¸ë¬¸ì—ë§Œ íƒ€ì´í‹€ ì ìš©")
        title_clip = create_highlighted_text_clip(
            title_text, fontsize=50, color='white', highlight_color='#00ff00',
            is_title=True, max_width=680
        )
        title_clip = title_clip.set_position(("center", 100)).set_duration(body_concat.duration)
        body_concat = CompositeVideoClip([body_concat, title_clip], size=final_size)
    
    # [3] ìµœì¢… ì‹œí€€ìŠ¤ ì¡°ë¦½: Intro -> Body -> Outro
    final_sequence = []
    
    if intro_clip_final:
        final_sequence.append(intro_clip_final)
        
    final_sequence.append(body_concat)
    
    if outro_clip_final:
        final_sequence.append(outro_clip_final)

    final_clip = concatenate_videoclips(final_sequence, method="compose")

    # ì €ì¥
    output_dir = "results"
    os.makedirs(output_dir, exist_ok=True)
    
    time_tag = datetime.now().strftime("%m%d_%H%M")
    base_name = "final_shorts" if is_shorts else "final_video"
    
    filename_timestamp = f"{base_name}_{time_tag}.mp4"
    filename_latest = f"{base_name}.mp4"
    
    output_path = os.path.join(output_dir, filename_timestamp)
    latest_path = os.path.join(output_dir, filename_latest)
    
    print(f"ğŸš€ ë Œë”ë§ ì‹œì‘: {output_path}")
    
    final_clip.write_videofile(
        output_path, 
        fps=24, 
        codec="libx264", 
        audio_codec="aac",
        threads=4,
        logger="bar"
    )
    
    shutil.copy2(output_path, latest_path)
    print(f"âœ¨ í¸ì§‘ ì™„ë£Œ! (ì €ì¥: {output_path})")

if __name__ == "__main__":
    create_video()