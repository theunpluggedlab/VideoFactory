import os
import json
import requests
from dotenv import load_dotenv
import google.generativeai as genai
import sys
from datetime import date, datetime
import re

# 1. ì„¤ì • ë° ë³€ìˆ˜
load_dotenv()

# API í‚¤ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ (Rotation - 4ê°œ)
GEMINI_KEYS = []
if os.environ.get("GEMINI_API_KEY"): GEMINI_KEYS.append(os.environ.get("GEMINI_API_KEY"))
if os.environ.get("GEMINI_API_KEY_2"): GEMINI_KEYS.append(os.environ.get("GEMINI_API_KEY_2"))
if os.environ.get("GEMINI_API_KEY_3"): GEMINI_KEYS.append(os.environ.get("GEMINI_API_KEY_3"))
if os.environ.get("GEMINI_API_KEY_4"): GEMINI_KEYS.append(os.environ.get("GEMINI_API_KEY_4"))

if not GEMINI_KEYS:
    print("âŒ ì˜¤ë¥˜: .env íŒŒì¼ì—ì„œ GEMINI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)

current_key_index = 0
print(f"ğŸ”‘ [Writer] ë¡œë“œëœ Gemini API í‚¤ ê°œìˆ˜: {len(GEMINI_KEYS)}")

# ì£¼ì œ ë° ëª¨ë“œ ì„¤ì •
if len(sys.argv) > 1:
    topic = sys.argv[1]
else:
    topic = "ì„œê¸° 2050ë…„, ì¸ê°„ê³¼ ì‚¬ë‘ì— ë¹ ì§„ AI ë¡œë´‡"

mode = "video"
if len(sys.argv) > 2:
    mode = sys.argv[2]

language = "ko"
if len(sys.argv) > 3:
    language = sys.argv[3]

def search_news_serper(query):
    """Serper APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ê²€ìƒ‰ (ì •ë³´ëŸ‰ ì¦ëŒ€: 20ê°œ)"""
    url = "https://google.serper.dev/news"
    serper_key = os.getenv("SERPER_API_KEY")
    if not serper_key:
        print("âš ï¸ SERPER_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. ë‰´ìŠ¤ ê²€ìƒ‰ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return ""
        
    payload = json.dumps({
        "q": query, "gl": "us", "hl": "en", "num": 20 
    })
    headers = {'X-API-KEY': serper_key, 'Content-Type': 'application/json'}
    
    try:
        response = requests.request("POST", url, headers=headers, data=payload)
        data = response.json()
        news_list = []
        if "news" in data:
            for item in data["news"]:
                source = item.get("source", "")
                title = item.get("title", "")
                snippet = item.get("snippet", "")
                date_ago = item.get("date", "")
                news_list.append(f"- [{source} | {date_ago}] {title}: {snippet}")
        return "\n".join(news_list)
    except Exception as e:
        print(f"âŒ Serper ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return ""

def generate_story():
    global current_key_index
    
    response = None 
    prompt = ""
    
    # ì–¸ì–´ ì„¤ì •
    if language == "en":
        narration_lang_instruction = "Write the narration script in **English**."
    else:
        narration_lang_instruction = "ëŒ€ë³¸(narration)ì„ **í•œêµ­ì–´**ë¡œ ì‘ì„±í•´. (ë‹¨, ì±„ë„ëª… 'Flash News Bite'ëŠ” ì˜ì–´ ê·¸ëŒ€ë¡œ ìœ ì§€)"

    today_str = date.today().strftime("%Y-%m-%d")

    # ---------------------------------------------------------
    # 2. í”„ë¡¬í”„íŠ¸ ì‘ì„± ë¡œì§
    # ---------------------------------------------------------
    if "news" in mode:
        # 1) ë‰´ìŠ¤ ëª¨ë“œ (Serper ì‚¬ìš©)
        news_context = ""
        source_type = ""
        
        if mode == "url_news_shorts":
            # URL ëª¨ë“œ
            print(f"ğŸ”— ê¸°ì‚¬ ë°ì´í„° ë¡œë“œ ì¤‘... (article_cache.json)")
            if not os.path.exists("article_cache.json"):
                print("âŒ article_cache.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            with open("article_cache.json", "r", encoding="utf-8") as f:
                article_data = json.load(f)
            article_text = article_data.get('text', '')
            if len(article_text) > 20000: article_text = article_text[:20000] + "..."
            news_context = f"Title: {article_data.get('title','')}\nContent:\n{article_text}"
            source_type = "Single Article"
            
        else:
            # ì¼ë°˜ ë‰´ìŠ¤ ëª¨ë“œ (Serper ê²€ìƒ‰)
            print(f"ğŸ“° ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘... (Serper: {topic})")
            
            if topic == "Today's Top News":
                news_query = f"Top essential breaking news headlines U.S. and World {today_str} summary"
            else:
                news_query = f"{topic} news updates {today_str}"
            
            news_context_raw = search_news_serper(news_query)
            if not news_context_raw: news_context_raw = "ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨. ì¼ë°˜ì ì¸ ìµœì‹  ë‰´ìŠ¤ë¡œ ìƒì„±."
            news_context = f"[Serper Search Results]\n{news_context_raw}"
            source_type = "News Search Results"

        # í¬ë§· ì„¤ì •
        is_shorts = "shorts" in mode
        
        if is_shorts:
            format_type = "**Shorts** script (45-60s)"
            length_cons = "Strictly 45-60 seconds. Structure into **8-12 short, snappy scenes**."
        else:
            format_type = "**Video** script (approx 3-4 mins)"
            length_cons = "Approx 3-4 minutes. Structure into 15-25 scenes."

        channel_desc = "Stay instantly informed with Flash News Bite! We bring you the dayâ€™s most important news, summarized in quick, easy-to-watch videos. Perfect for viewers who want authentic updates on top world, U.S., and trending storiesâ€”without the clutter."

        prompt = f"""
        You are the lead editor and social media manager for the news channel "**Flash News Bite**".
        Channel Mission: "{channel_desc}"
        
        Task: Generate a complete content package for a YouTube {format_type}.
        Based on: {source_type} data provided below.
        Date: {today_str}
        
        [Input Data]
        {news_context}
        
        [Instructions & Constraints]
        1. **Content**: Focus ONLY on today's Top Must-Know events.
        2. **Format Constraint**: {length_cons}
        3. **Scene Pacing**: Each scene's narration must be **maximum 2 sentences long**.
        4. **Language**: {narration_lang_instruction}
        5. **Formatting**: NO EMOJIS in narration. Wrap **KEYWORDS** in asterisks `*`.
        
        6. **MANDATORY INTRO (Scene 1)**: 
           - Start with a short, punchy hook (1 sentence) welcoming viewers to "**Flash News Bite**".
           - **CRITICAL**: Vary the wording every time to sound fresh.
           - Image Prompt: "Flash News Bite logo, news studio background, professional, 3d render"

        7. **MANDATORY OUTRO (Last Scene)**: 
           - End with a dynamic sign-off mentioning "**Flash News Bite**".
           - Ask to Like, Subscribe, and Comment.
           - **CRITICAL**: Vary the wording every time.
           - Image Prompt: "YouTube Subscribe button and Like icon, Flash News Bite theme, neon lighting, high quality"
        
        [Output Requirement - Social Media Package (CRITICAL)]
        You must generate optimized posts for EACH platform in the `social_posts` JSON section.
        Use English for social posts unless the topic is local.
        
        1. **YouTube Post**:
           - **Title**: Clickable, under 100 chars, include #Shorts + keywords.
           - **Description**: 
             - Hook paragraph.
             - Detailed summary body (2 paragraphs).
             - Engagement question (e.g., "What do you think?").
             - **CTAs**: Use ğŸ‘‰ icon. (e.g., "ğŸ‘‰ Hit LIKE, ğŸ‘‰ SUBSCRIBE, ğŸ‘‰ SHARE").
             - **Hashtags**: List of relevant tags.
        
        2. **X (Twitter)**: Under 280 chars, punchy summary, relevant emojis, 3-5 hashtags.
        3. **Threads**: Conversational tone, slightly longer than X, storytelling style, hashtags.
        4. **Instagram**: Visual hook line, detailed caption, question for engagement. CTAs: "â¤ï¸ Save this post", "ğŸ’¬ Drop your thoughts". Wall of hashtags.
        5. **TikTok**: Very short hook, "Watch till the end", viral tags like #fyp #foryou #breakingnews.

        Strictly output valid JSON:
        {{
            "title": "YouTube Title",
            "description": "YouTube Description",
            "hashtags": "YouTube Hashtags",
            "scenes": [ ... ],
            "social_posts": {{
                "youtube_title": "...",
                "youtube_description": "...",
                "x_post": "...",
                "threads_post": "...",
                "instagram_caption": "...",
                "tiktok_caption": "..."
            }}
        }}
        """
        
    else:
        # ì°½ì‘ ëª¨ë“œ
        is_shorts = ("shorts" in mode) or ("shorts" in topic.lower())
        duration_instruction = "Shorts ëª¨ë“œ: 50ì´ˆ ì´ë‚´, ì¥ë©´ 8ê°œ ì´ìƒ." if is_shorts else ""
        prompt = f"""
        Topic: "{topic}"
        Create a story script.
        {duration_instruction}
        Language: {narration_lang_instruction}
        Output strictly JSON.
        """

    # ---------------------------------------------------------
    # 3. ëª¨ë¸ ì‹¤í–‰ (Key Rotation)
    # ---------------------------------------------------------
    print(f"ğŸ¤– Gemini ëª¨ë¸ í˜¸ì¶œ ì¤‘... (Mode: {mode})")
    
    attempts = 0
    max_attempts = len(GEMINI_KEYS)
    
    while attempts < max_attempts:
        current_key = GEMINI_KEYS[current_key_index]
        try:
            # WriterëŠ” ê¸°ì¡´ google-generativeai ì‚¬ìš© (ì•ˆì •ì„±)
            genai.configure(api_key=current_key)
            generation_config = {
                "temperature": 0.7,
                "top_p": 0.95, "top_k": 40, 
                "max_output_tokens": 8192, "response_mime_type": "application/json"
            }
            model = genai.GenerativeModel(
                model_name="gemini-2.0-flash", 
                generation_config=generation_config
            )
            
            response = model.generate_content(prompt)
            break 
            
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg or "QuotaExceeded" in error_msg:
                print(f"âš ï¸ [Key {current_key_index+1}] ì¿¼í„° ì´ˆê³¼! ë‹¤ìŒ í‚¤ë¡œ êµì²´...")
                current_key_index = (current_key_index + 1) % len(GEMINI_KEYS)
                attempts += 1
                continue
            else:
                print(f"âŒ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                attempts += 1
                continue

    if not response:
        print("âŒ ì‹¤íŒ¨: ëª¨ë“  API í‚¤ê°€ ì†Œì§„ë˜ì—ˆê±°ë‚˜ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)

    text = response.text
    text = re.sub(r'^```json\s*', '', text, flags=re.MULTILINE)
    text = re.sub(r'\s*```$', '', text, flags=re.MULTILINE)
        
    try:
        parsed_data = json.loads(text)
        final_data = parsed_data if isinstance(parsed_data, list) else [parsed_data]
        
        with open("story.json", "w", encoding="utf-8") as f:
            json.dump(final_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… story.json ì €ì¥ ì™„ë£Œ (Scenes: {len(final_data[0].get('scenes', []))})")
        
        if "news" in mode:
            output_dir = "results"
            os.makedirs(output_dir, exist_ok=True)
            
            # [í•µì‹¬] JSONì—ì„œ ì†Œì…œ ë¯¸ë””ì–´ ë°ì´í„° ì¶”ì¶œ
            socials = parsed_data.get("social_posts", {})
            
            # [ë©”íƒ€ë°ì´í„° ì €ì¥ ë¡œì§ ê°•í™”]
            meta_content = ""
            
            # 1. YouTube
            yt_title = socials.get("youtube_title") or parsed_data.get("title", "")
            yt_desc = socials.get("youtube_description") or parsed_data.get("description", "")
            
            meta_content += "========================================\n"
            meta_content += "[YOUTUBE]\n"
            meta_content += f"TITLE:\n{yt_title}\n\n"
            meta_content += f"DESCRIPTION:\n{yt_desc}\n\n"
            meta_content += f"HASHTAGS:\n{parsed_data.get('hashtags', '')}\n"
            meta_content += "========================================\n\n"
            
            # 2. X (Twitter)
            meta_content += "[X.COM / TWITTER]\n"
            meta_content += f"{socials.get('x_post', 'N/A')}\n\n"

            # 3. Threads
            meta_content += "[THREADS]\n"
            meta_content += f"{socials.get('threads_post', 'N/A')}\n\n"
            
            # 4. Instagram
            meta_content += "[INSTAGRAM]\n"
            meta_content += f"{socials.get('instagram_caption', 'N/A')}\n\n"
            
            # 5. TikTok
            meta_content += "[TIKTOK]\n"
            meta_content += f"{socials.get('tiktok_caption', 'N/A')}\n"
            
            time_tag = datetime.now().strftime("%m%d_%H%M")
            meta_path = os.path.join(output_dir, f"metadata_{time_tag}.txt")
            
            with open(meta_path, "w", encoding="utf-8") as f:
                f.write(meta_content)
            print(f"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {meta_path}")

    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        print(text[:500])

if __name__ == "__main__":
    generate_story()