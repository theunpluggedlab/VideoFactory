import os
import json
import requests
from dotenv import load_dotenv
import google.generativeai as genai
import sys
from datetime import date, datetime
import re
import time

# 1. ÏÑ§Ï†ï Î∞è Î≥ÄÏàò
load_dotenv()

# API ÌÇ§ 5Í∞ú Î°úÎìú
GEMINI_KEYS = []
if os.environ.get("GEMINI_API_KEY"): GEMINI_KEYS.append(os.environ.get("GEMINI_API_KEY"))
if os.environ.get("GEMINI_API_KEY_2"): GEMINI_KEYS.append(os.environ.get("GEMINI_API_KEY_2"))
if os.environ.get("GEMINI_API_KEY_3"): GEMINI_KEYS.append(os.environ.get("GEMINI_API_KEY_3"))
if os.environ.get("GEMINI_API_KEY_4"): GEMINI_KEYS.append(os.environ.get("GEMINI_API_KEY_4"))
if os.environ.get("GEMINI_API_KEY_5"): GEMINI_KEYS.append(os.environ.get("GEMINI_API_KEY_5"))

if not GEMINI_KEYS:
    print("‚ùå Ïò§Î•ò: .env ÌååÏùºÏóêÏÑú GEMINI_API_KEYÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
    sys.exit(1)

current_key_index = 0
print(f"üîë [Writer] Î°úÎìúÎêú Gemini API ÌÇ§ Í∞úÏàò: {len(GEMINI_KEYS)}Í∞ú")

# Ï£ºÏ†ú Î∞è Î™®Îìú ÏÑ§Ï†ï
if len(sys.argv) > 1:
    topic = sys.argv[1]
else:
    topic = "ÏÑúÍ∏∞ 2050ÎÖÑ, Ïù∏Í∞ÑÍ≥º ÏÇ¨ÎûëÏóê Îπ†ÏßÑ AI Î°úÎ¥á"

mode = "video"
if len(sys.argv) > 2:
    mode = sys.argv[2]

language = "ko"
if len(sys.argv) > 3:
    language = sys.argv[3]

def search_news_serper(query):
    url = "https://google.serper.dev/news"
    serper_key = os.getenv("SERPER_API_KEY")
    if not serper_key:
        print("‚ö†Ô∏è SERPER_API_KEYÍ∞Ä ÏóÜÏäµÎãàÎã§. Îâ¥Ïä§ Í≤ÄÏÉâÏùÑ Í±¥ÎÑàÎúÅÎãàÎã§.")
        return ""
        
    payload = json.dumps({
        "q": query, "gl": "us", "hl": "en", "num": 20 
    })
    headers = {'X-API-KEY': serper_key, 'Content-Type': 'application/json'}
    
    try:
        response = requests.request("POST", url, headers=headers, data=payload)
        data = response.json()
        news_list = []
        if "news" in data:
            for item in data["news"]:
                source = item.get("source", "")
                title = item.get("title", "")
                snippet = item.get("snippet", "")
                date_ago = item.get("date", "")
                news_list.append(f"- [{source} | {date_ago}] {title}: {snippet}")
        return "\n".join(news_list)
    except Exception as e:
        print(f"‚ùå Serper Îâ¥Ïä§ Í≤ÄÏÉâ Ïã§Ìå®: {e}")
        return ""

def generate_story():
    global current_key_index
    
    response = None 
    prompt = ""
    
    if language == "en":
        narration_lang_instruction = "Write the narration script in **English**."
    else:
        narration_lang_instruction = "ÎåÄÎ≥∏(narration)ÏùÑ **ÌïúÍµ≠Ïñ¥**Î°ú ÏûëÏÑ±Ìï¥. (Îã®, Ï±ÑÎÑêÎ™Ö 'Flash News Bite'Îäî ÏòÅÏñ¥ Í∑∏ÎåÄÎ°ú Ïú†ÏßÄ)"

    today_str = date.today().strftime("%Y-%m-%d")

    # ÌîÑÎ°¨ÌîÑÌä∏ ÏûëÏÑ±
    if "news" in mode:
        news_context = ""
        source_type = ""
        
        if mode == "url_news_shorts":
            print(f"üîó Í∏∞ÏÇ¨ Îç∞Ïù¥ÌÑ∞ Î°úÎìú Ï§ë... (article_cache.json)")
            if not os.path.exists("article_cache.json"):
                print("‚ùå article_cache.json ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§.")
                return
            with open("article_cache.json", "r", encoding="utf-8") as f:
                article_data = json.load(f)
            article_text = article_data.get('text', '')
            if len(article_text) > 20000: article_text = article_text[:20000] + "..."
            news_context = f"Title: {article_data.get('title','')}\nContent:\n{article_text}"
            source_type = "Single Article"
            
        else:
            print(f"üì∞ ÏµúÏã† Îâ¥Ïä§ Í≤ÄÏÉâ Ï§ë... (Serper: {topic})")
            if topic == "Today's Top News":
                news_query = f"Top essential breaking news headlines U.S. and World {today_str} summary"
            else:
                news_query = f"{topic} news updates {today_str}"
            
            news_context_raw = search_news_serper(news_query)
            if not news_context_raw: news_context_raw = "Îâ¥Ïä§ Í≤ÄÏÉâ Ïã§Ìå®. ÏùºÎ∞òÏ†ÅÏù∏ ÏµúÏã† Îâ¥Ïä§Î°ú ÏÉùÏÑ±."
            news_context = f"[Serper Search Results]\n{news_context_raw}"
            source_type = "News Search Results"

        is_shorts = "shorts" in mode
        
        if is_shorts:
            format_type = "**Shorts** script (45-60s)"
            length_cons = "Strictly 45-60 seconds. Structure into **8-12 short, snappy scenes**."
        else:
            format_type = "**Video** script (approx 3-4 mins)"
            length_cons = "Approx 3-4 minutes. Structure into 15-25 scenes."

        channel_desc = "Stay instantly informed with Flash News Bite! We bring you the day‚Äôs most important news, summarized in quick, easy-to-watch videos. Perfect for viewers who want authentic updates on top world, U.S., and trending stories‚Äîwithout the clutter."

        prompt = f"""
        You are the lead editor and social media manager for the news channel "**Flash News Bite**".
        Channel Mission: "{channel_desc}"
        
        Task: Generate a complete content package for a YouTube {format_type}.
        Based on: {source_type} data provided below.
        Date: {today_str}
        
        [Input Data]
        {news_context}
        
        [Instructions & Constraints]
        1. **Content**: Focus ONLY on today's Top Must-Know events.
        2. **Format Constraint**: {length_cons}
        3. **Scene Pacing**: Each scene's narration must be **maximum 2 sentences long**.
        4. **Language**: {narration_lang_instruction}
        5. **Formatting**: NO EMOJIS in narration. Wrap **KEYWORDS** in asterisks `*`.
        
        6. **MANDATORY INTRO (Scene 1)**: 
           - Start with a short, punchy hook (1 sentence) welcoming viewers to "**Flash News Bite**".
           - **CRITICAL**: Vary the wording every time to sound fresh.
           - Image Prompt: "Flash News Bite logo, news studio background, professional, 3d render"

        7. **MANDATORY OUTRO (Last Scene)**: 
           - End with a dynamic sign-off mentioning "**Flash News Bite**".
           - Ask to Like, Subscribe, and Comment.
           - **CRITICAL**: Vary the wording every time.
           - Image Prompt: "YouTube Subscribe button and Like icon, Flash News Bite theme, neon lighting, high quality"
        
        [Output Requirement - Social Media Package (CRITICAL)]
        You must generate optimized posts for EACH platform in the `social_posts` JSON section.
        Use English for social posts unless the topic is local.
        
        1. **YouTube Post**:
           - **Title**: Clickable, under 100 chars, include #Shorts + keywords.
           - **Description**: 
             - Hook paragraph.
             - Detailed summary body (2 paragraphs).
             - Engagement question (e.g., "What do you think?").
             - **CTAs**: Use üëâ icon. (e.g., "üëâ Hit LIKE, üëâ SUBSCRIBE, üëâ SHARE").
             - **Hashtags**: List of relevant tags.
        
        2. **X (Twitter)**: Under 280 chars, punchy summary, relevant emojis, 3-5 hashtags.
        3. **Threads**: Conversational tone, slightly longer than X, storytelling style, hashtags.
        4. **Instagram**: Visual hook line, detailed caption, question for engagement. CTAs: "‚ù§Ô∏è Save this post", "üí¨ Drop your thoughts". Wall of hashtags.
        5. **TikTok**: Very short hook, "Watch till the end", viral tags like #fyp #foryou #breakingnews.

        Strictly output valid JSON:
        {{
            "title": "YouTube Title",
            "description": "YouTube Description",
            "hashtags": "YouTube Hashtags",
            "scenes": [ ... ],
            "social_posts": {{
                "youtube_title": "...",
                "youtube_description": "...",
                "x_post": "...",
                "threads_post": "...",
                "instagram_caption": "...",
                "tiktok_caption": "..."
            }}
        }}
        """
        
    else:
        is_shorts = ("shorts" in mode) or ("shorts" in topic.lower())
        duration_instruction = "Shorts Î™®Îìú: 50Ï¥à Ïù¥ÎÇ¥, Ïû•Î©¥ 8Í∞ú Ïù¥ÏÉÅ." if is_shorts else ""
        prompt = f"""
        Topic: "{topic}"
        Create a story script.
        {duration_instruction}
        Language: {narration_lang_instruction}
        Output strictly JSON.
        """

    # ---------------------------------------------------------
    # 3. Î™®Îç∏ Ïã§Ìñâ (Gemini 3.0 Flash Preview)
    # ---------------------------------------------------------
    
    # [ÏÑ§Ï†ï] 3.0 Î™®Îç∏ Ï†ÅÏö©
    MODEL_NAME = "gemini-3-flash-preview"
    print(f"ü§ñ Gemini Î™®Îç∏ Ìò∏Ï∂ú Ï§ë... (Model: {MODEL_NAME})")
    
    attempts = 0
    max_attempts = len(GEMINI_KEYS) * 2
    
    while attempts < max_attempts:
        current_key = GEMINI_KEYS[current_key_index]
        try:
            genai.configure(api_key=current_key)
            generation_config = {
                "temperature": 0.7,
                "top_p": 0.95, "top_k": 40, 
                "max_output_tokens": 8192, "response_mime_type": "application/json"
            }
            model = genai.GenerativeModel(
                model_name=MODEL_NAME, 
                generation_config=generation_config
            )
            
            response = model.generate_content(prompt)
            break 
            
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg or "QuotaExceeded" in error_msg:
                print(f"‚ö†Ô∏è [Key #{current_key_index+1}] ÏøºÌÑ∞ Ï¥àÍ≥º! Îã§Ïùå ÌÇ§Î°ú ÍµêÏ≤¥...")
                current_key_index = (current_key_index + 1) % len(GEMINI_KEYS)
                attempts += 1
                time.sleep(2)
                continue
            else:
                print(f"‚ùå API Ìò∏Ï∂ú Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}")
                attempts += 1
                continue

    if not response:
        print("‚ùå Ïã§Ìå®: Î™®Îì† API ÌÇ§Í∞Ä ÏÜåÏßÑÎêòÏóàÍ±∞ÎÇò ÏùëÎãµÏùÑ Î∞õÏßÄ Î™ªÌñàÏäµÎãàÎã§.")
        sys.exit(1)

    text = response.text
    text = re.sub(r'^```json\s*', '', text, flags=re.MULTILINE)
    text = re.sub(r'\s*```$', '', text, flags=re.MULTILINE)
        
    try:
        parsed_data = json.loads(text)
        final_data = parsed_data if isinstance(parsed_data, list) else [parsed_data]
        
        with open("story.json", "w", encoding="utf-8") as f:
            json.dump(final_data, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ story.json Ï†ÄÏû• ÏôÑÎ£å (Scenes: {len(final_data[0].get('scenes', []))})")
        
        if "news" in mode:
            output_dir = "results"
            os.makedirs(output_dir, exist_ok=True)
            
            socials = parsed_data.get("social_posts", {})
            meta_content = ""
            
            yt_title = socials.get("youtube_title") or parsed_data.get("title", "")
            yt_desc = socials.get("youtube_description") or parsed_data.get("description", "")
            
            meta_content += "========================================\n"
            meta_content += "[YOUTUBE]\n"
            meta_content += f"TITLE:\n{yt_title}\n\n"
            meta_content += f"DESCRIPTION:\n{yt_desc}\n\n"
            meta_content += f"HASHTAGS:\n{parsed_data.get('hashtags', '')}\n"
            meta_content += "========================================\n\n"
            
            meta_content += "[X.COM / TWITTER]\n"
            meta_content += f"{socials.get('x_post', 'N/A')}\n\n"

            meta_content += "[THREADS]\n"
            meta_content += f"{socials.get('threads_post', 'N/A')}\n\n"
            
            meta_content += "[INSTAGRAM]\n"
            meta_content += f"{socials.get('instagram_caption', 'N/A')}\n\n"
            
            meta_content += "[TIKTOK]\n"
            meta_content += f"{socials.get('tiktok_caption', 'N/A')}\n"
            
            time_tag = datetime.now().strftime("%m%d_%H%M")
            meta_path = os.path.join(output_dir, f"metadata_{time_tag}.txt")
            
            with open(meta_path, "w", encoding="utf-8") as f:
                f.write(meta_content)
            print(f"‚úÖ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï†ÄÏû• ÏôÑÎ£å: {meta_path}")

    except json.JSONDecodeError as e:
        print(f"‚ùå JSON ÌååÏã± Ïò§Î•ò: {e}")
        print(text[:500])

if __name__ == "__main__":
    generate_story()